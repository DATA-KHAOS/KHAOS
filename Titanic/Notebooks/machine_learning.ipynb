{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando Bibliotecas & os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>...</th>\n",
       "      <th>is_male</th>\n",
       "      <th>cabin_group</th>\n",
       "      <th>title</th>\n",
       "      <th>last_name</th>\n",
       "      <th>family_size</th>\n",
       "      <th>fare_group</th>\n",
       "      <th>is_alone</th>\n",
       "      <th>ticket_length</th>\n",
       "      <th>ticket_qtd</th>\n",
       "      <th>sex_pclass_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Unk</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unk</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Braund</td>\n",
       "      <td>2</td>\n",
       "      <td>Low Fare</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>male_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Cumings</td>\n",
       "      <td>2</td>\n",
       "      <td>High Fare</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>female_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Unk</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Unk</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Heikkinen</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium-Low Fare</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>female_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Futrelle</td>\n",
       "      <td>2</td>\n",
       "      <td>High Fare</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>female_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Unk</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unk</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Allen</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium-Low Fare</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>male_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Juozas</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Unk</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unk</td>\n",
       "      <td>Rev</td>\n",
       "      <td>Montvila</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium-Low Fare</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>male_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Margaret Edith</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Graham</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium-High Fare</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>female_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Catherine Helen \"Carrie\"</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>Unk</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Unk</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Johnston</td>\n",
       "      <td>4</td>\n",
       "      <td>Medium-High Fare</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>female_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Karl Howell</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Behr</td>\n",
       "      <td>1</td>\n",
       "      <td>Medium-High Fare</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>male_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Patrick</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Unk</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>Unk</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Dooley</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Fare</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>male_3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passengerid  survived  pclass                                   name  \\\n",
       "0              1         0       3                            Owen Harris   \n",
       "1              2         1       1  John Bradley (Florence Briggs Thayer)   \n",
       "2              3         1       3                                  Laina   \n",
       "3              4         1       1          Jacques Heath (Lily May Peel)   \n",
       "4              5         0       3                          William Henry   \n",
       "..           ...       ...     ...                                    ...   \n",
       "886          887         0       2                                 Juozas   \n",
       "887          888         1       1                         Margaret Edith   \n",
       "888          889         0       3               Catherine Helen \"Carrie\"   \n",
       "889          890         1       1                            Karl Howell   \n",
       "890          891         0       3                                Patrick   \n",
       "\n",
       "      age  sibsp  parch            ticket     fare cabin  ...  is_male  \\\n",
       "0    22.0      1      0         A/5 21171   7.2500   Unk  ...        1   \n",
       "1    38.0      1      0          PC 17599  71.2833   C85  ...        0   \n",
       "2    26.0      0      0  STON/O2. 3101282   7.9250   Unk  ...        0   \n",
       "3    35.0      1      0            113803  53.1000  C123  ...        0   \n",
       "4    35.0      0      0            373450   8.0500   Unk  ...        1   \n",
       "..    ...    ...    ...               ...      ...   ...  ...      ...   \n",
       "886  27.0      0      0            211536  13.0000   Unk  ...        1   \n",
       "887  19.0      0      0            112053  30.0000   B42  ...        0   \n",
       "888  13.5      1      2        W./C. 6607  23.4500   Unk  ...        0   \n",
       "889  26.0      0      0            111369  30.0000  C148  ...        1   \n",
       "890  32.0      0      0            370376   7.7500   Unk  ...        1   \n",
       "\n",
       "     cabin_group  title  last_name  family_size        fare_group is_alone  \\\n",
       "0            Unk     Mr     Braund            2          Low Fare        0   \n",
       "1              C    Mrs    Cumings            2         High Fare        0   \n",
       "2            Unk   Miss  Heikkinen            1   Medium-Low Fare        1   \n",
       "3              C    Mrs   Futrelle            2         High Fare        0   \n",
       "4            Unk     Mr      Allen            1   Medium-Low Fare        1   \n",
       "..           ...    ...        ...          ...               ...      ...   \n",
       "886          Unk    Rev   Montvila            1   Medium-Low Fare        1   \n",
       "887            B   Miss     Graham            1  Medium-High Fare        1   \n",
       "888          Unk   Miss   Johnston            4  Medium-High Fare        0   \n",
       "889            C     Mr       Behr            1  Medium-High Fare        1   \n",
       "890          Unk     Mr     Dooley            1          Low Fare        1   \n",
       "\n",
       "    ticket_length  ticket_qtd sex_pclass_interaction  \n",
       "0               9           1                 male_3  \n",
       "1               8           1               female_1  \n",
       "2              16           1               female_3  \n",
       "3               6           2               female_1  \n",
       "4               6           1                 male_3  \n",
       "..            ...         ...                    ...  \n",
       "886             6           1                 male_2  \n",
       "887             6           1               female_1  \n",
       "888            10           2               female_3  \n",
       "889             6           1                 male_1  \n",
       "890             6           1                 male_3  \n",
       "\n",
       "[891 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define o caminho relativo\n",
    "file_path = os.path.join('..', 'Data', 'processed_data.csv')  # '..' sobe um nível de diretório\n",
    "\n",
    "# Carrega os dados\n",
    "df = pd.read_csv(file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passengerid', 'survived', 'pclass', 'name', 'age', 'sibsp', 'parch',\n",
       "       'ticket', 'fare', 'cabin', 'embarked_c', 'embarked_q', 'embarked_s',\n",
       "       'age_group', 'is_male', 'cabin_group', 'title', 'last_name',\n",
       "       'family_size', 'fare_group', 'is_alone', 'ticket_length', 'ticket_qtd',\n",
       "       'sex_pclass_interaction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   passengerid             891 non-null    int64  \n",
      " 1   survived                891 non-null    int64  \n",
      " 2   pclass                  891 non-null    int64  \n",
      " 3   name                    891 non-null    object \n",
      " 4   age                     891 non-null    float64\n",
      " 5   sibsp                   891 non-null    int64  \n",
      " 6   parch                   891 non-null    int64  \n",
      " 7   ticket                  891 non-null    object \n",
      " 8   fare                    891 non-null    float64\n",
      " 9   cabin                   891 non-null    object \n",
      " 10  embarked_c              891 non-null    int64  \n",
      " 11  embarked_q              891 non-null    int64  \n",
      " 12  embarked_s              891 non-null    int64  \n",
      " 13  age_group               891 non-null    object \n",
      " 14  is_male                 891 non-null    int64  \n",
      " 15  cabin_group             891 non-null    object \n",
      " 16  title                   891 non-null    object \n",
      " 17  last_name               891 non-null    object \n",
      " 18  family_size             891 non-null    int64  \n",
      " 19  fare_group              876 non-null    object \n",
      " 20  is_alone                891 non-null    int64  \n",
      " 21  ticket_length           891 non-null    int64  \n",
      " 22  ticket_qtd              891 non-null    int64  \n",
      " 23  sex_pclass_interaction  891 non-null    object \n",
      "dtypes: float64(2), int64(13), object(9)\n",
      "memory usage: 167.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def transform_specific_columns_to_int(df):\n",
    "    # Especifica as colunas que queremos transformar\n",
    "    specific_cols = ['age_group', 'cabin_group', 'title', 'fare_group', 'sex_pclass_interaction']\n",
    "    \n",
    "    # Verifica se as colunas existem no DataFrame\n",
    "    specific_cols = [col for col in specific_cols if col in df.columns]\n",
    "    \n",
    "    # Aplica get_dummies para transformar as colunas específicas em colunas numéricas\n",
    "    df_transformed = pd.get_dummies(df, columns=specific_cols, drop_first=True)\n",
    "    \n",
    "    return df_transformed\n",
    "\n",
    "# Exemplo de uso\n",
    "# df é o seu DataFrame original\n",
    "df = transform_specific_columns_to_int(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['passengerid', 'survived', 'pclass', 'name', 'age', 'sibsp', 'parch',\n",
       "       'ticket', 'fare', 'cabin', 'embarked_c', 'embarked_q', 'embarked_s',\n",
       "       'is_male', 'last_name', 'family_size', 'is_alone', 'ticket_length',\n",
       "       'ticket_qtd', 'age_group_Baby', 'age_group_Child', 'age_group_Elderly',\n",
       "       'age_group_Pre-Teen', 'age_group_Senior', 'age_group_Teenager',\n",
       "       'age_group_Young Adult', 'cabin_group_B', 'cabin_group_C',\n",
       "       'cabin_group_D', 'cabin_group_E', 'cabin_group_F', 'cabin_group_G',\n",
       "       'cabin_group_T', 'cabin_group_Unk', 'title_Col', 'title_Don',\n",
       "       'title_Dr', 'title_Jonkheer', 'title_Lady', 'title_Major',\n",
       "       'title_Master', 'title_Miss', 'title_Mlle', 'title_Mme', 'title_Mr',\n",
       "       'title_Mrs', 'title_Ms', 'title_Rev', 'title_Sir', 'title_the Countess',\n",
       "       'fare_group_Low Fare', 'fare_group_Medium-High Fare',\n",
       "       'fare_group_Medium-Low Fare', 'sex_pclass_interaction_female_2',\n",
       "       'sex_pclass_interaction_female_3', 'sex_pclass_interaction_male_1',\n",
       "       'sex_pclass_interaction_male_2', 'sex_pclass_interaction_male_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supondo que já tenha os dados no df\n",
    "features = ['pclass', 'age', 'sibsp', 'parch',\n",
    "       'embarked_c', 'embarked_q', 'embarked_s',\n",
    "       'is_male', 'family_size', 'is_alone', 'ticket_length',\n",
    "       'ticket_qtd', 'age_group_Baby', 'age_group_Child', 'age_group_Elderly',\n",
    "       'age_group_Pre-Teen', 'age_group_Senior', 'age_group_Teenager',\n",
    "       'age_group_Young Adult', 'cabin_group_B', 'cabin_group_C',\n",
    "       'cabin_group_D', 'cabin_group_E', 'cabin_group_F', 'cabin_group_G',\n",
    "       'cabin_group_T', 'cabin_group_Unk', 'title_Col', 'title_Don',\n",
    "       'title_Dr', 'title_Jonkheer', 'title_Lady', 'title_Major',\n",
    "       'title_Master', 'title_Miss', 'title_Mlle', 'title_Mme', 'title_Mr',\n",
    "       'title_Mrs', 'title_Ms', 'title_Rev', 'title_Sir', 'title_the Countess',\n",
    "       'fare_group_Low Fare', 'fare_group_Medium-High Fare',\n",
    "       'fare_group_Medium-Low Fare', 'sex_pclass_interaction_female_2',\n",
    "       'sex_pclass_interaction_female_3', 'sex_pclass_interaction_male_1',\n",
    "       'sex_pclass_interaction_male_2', 'sex_pclass_interaction_male_3']\n",
    "target = 'survived'\n",
    "\n",
    "# Codificar variáveis categóricas usando One-Hot Encoding\n",
    "X = df[features]\n",
    "#X = pd.get_dummies(df[features], drop_first=True)\n",
    "y = df[target]\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Acurácia: 0.8101\n",
      "CatBoost Acurácia: 0.8268\n",
      "XGBoost Acurácia: 0.8101\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 268, number of negative: 444\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 181\n",
      "[LightGBM] [Info] Number of data points in the train set: 712, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.376404 -> initscore=-0.504838\n",
      "[LightGBM] [Info] Start training from score -0.504838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Acurácia: 0.8101\n",
      "NeuralNetwork Acurácia: 0.8268\n",
      "Ensemble Acurácia: 0.8156\n",
      "\n",
      "Melhor modelo: CatBoost com Acurácia: 0.8268\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def train_models(X, y):\n",
    "    # Dividir os dados em conjuntos de treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Definir os modelos\n",
    "    models = {\n",
    "        'RandomForest': RandomForestClassifier(random_state=42),\n",
    "        'CatBoost': CatBoostClassifier(verbose=0, random_state=42),\n",
    "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        'LightGBM': LGBMClassifier(random_state=42),\n",
    "        'NeuralNetwork': MLPClassifier(max_iter=1000, random_state=42),\n",
    "    }\n",
    "    \n",
    "    # Criar um modelo ensemble\n",
    "    ensemble_model = VotingClassifier(estimators=[\n",
    "        ('rf', models['RandomForest']),\n",
    "        ('xgb', models['XGBoost']),\n",
    "        ('nn', models['NeuralNetwork']),\n",
    "    ], voting='hard')\n",
    "    \n",
    "    models['Ensemble'] = ensemble_model\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    \n",
    "    # Treinar e avaliar cada modelo\n",
    "    for model_name, model in models.items():\n",
    "        # Treinar o modelo\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Fazer previsões\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calcular a acurácia\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"{model_name} Acurácia: {accuracy:.4f}\")\n",
    "        \n",
    "        # Verificar se esse é o melhor modelo\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = model\n",
    "            best_model_name = model_name\n",
    "    \n",
    "    print(f\"\\nMelhor modelo: {best_model_name} com Acurácia: {best_accuracy:.4f}\")\n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "# Chamar a função\n",
    "best_model = train_models(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.8455056\ttest: 0.8268156\tbest: 0.8268156 (0)\ttotal: 10.7ms\tremaining: 1m 46s\n",
      "100:\tlearn: 0.8609551\ttest: 0.8268156\tbest: 0.8324022 (12)\ttotal: 636ms\tremaining: 1m 2s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 0.8324022346\n",
      "bestIteration = 12\n",
      "\n",
      "Shrink model to first 13 iterations.\n",
      "Acurácia do modelo CatBoost complexo: 0.8324\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "# Definir os parâmetros do CatBoost\n",
    "params = {\n",
    "    'iterations': 10000,           # Número de iterações\n",
    "    'learning_rate': 0.005,        # Taxa de aprendizado\n",
    "    'depth': 12,                   # Profundidade da árvore\n",
    "    'loss_function': 'Logloss',   # Função de perda\n",
    "    'eval_metric': 'Accuracy',    # Métrica de avaliação\n",
    "    'random_seed': 42,            # Semente para reprodução\n",
    "    'early_stopping_rounds': 100,  # Parar cedo se não houver melhora\n",
    "    'verbose': 100                # Mostrar informações a cada 100 iterações\n",
    "}\n",
    "\n",
    "# Criar pool de dados\n",
    "train_pool = Pool(X_train, y_train)\n",
    "test_pool = Pool(X_test, y_test)\n",
    "\n",
    "# Treinar o modelo\n",
    "model = CatBoostClassifier(**params)\n",
    "model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo CatBoost complexo: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Definir os parâmetros para o Grid Search\n",
    "params = {\n",
    "    'iterations': 10000,           # Número de iterações\n",
    "    'learning_rate': 0.005,        # Taxa de aprendizado\n",
    "    'depth': 12,                   # Profundidade da árvore\n",
    "    'loss_function': 'Logloss',   # Função de perda\n",
    "    'eval_metric': 'Accuracy',    # Métrica de avaliação\n",
    "    'random_seed': 42,            # Semente para reprodução\n",
    "    'early_stopping_rounds': 100,  # Parar cedo se não houver melhora\n",
    "    'verbose': 100                # Mostrar informações a cada 100 iterações\n",
    "}\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "grid_params = {\n",
    "    'iterations': [ 5000, 10000, 20000],  # Número de iterações\n",
    "    'learning_rate': [0.001, 0.005, 0.01],  # Taxa de aprendizado\n",
    "    'depth': [12, 20, 30, 40],\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Criar o Grid Search\n",
    "grid_search = GridSearchCV(estimator=model,\n",
    "                           param_grid=grid_params,\n",
    "                           scoring='accuracy',\n",
    "                           cv=3,                      # Número de folds para validação cruzada\n",
    "                           n_jobs=-1,                # Usar todos os núcleos disponíveis\n",
    "                           verbose=1)                # Mostrar progresso\n",
    "\n",
    "# Treinar o modelo com Grid Search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obter o melhor modelo e seus parâmetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_\n",
    "\n",
    "print(f\"\\nMelhores parâmetros: {best_params}\")\n",
    "print(f\"Melhor acurácia (validação cruzada): {best_accuracy:.4f}\")\n",
    "\n",
    "# Fazer previsões com o melhor modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular a acurácia no conjunto de teste\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo CatBoost no conjunto de teste: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão da importância e direção das características mais influentes segundo o modelo xgboost\n",
    "\n",
    "* Vemos que as colunas relacionadas a pessoa ser um homem tem uma influência negativa forte na sobrevivencia.\n",
    "\n",
    "* Vemos que pclass tem uma influência positiva, significando que a primeira classe tinha mais chance de sobreviver.\n",
    "\n",
    "* Quanto maior a taxa paga na passagem maior a chance de sobreviver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# Escalonar as características\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Construir o modelo de rede neural\n",
    "model = Sequential()\n",
    "\n",
    "# Adicionando camadas densas\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.2))  # Regularização com Dropout\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(np.unique(y)), activation='softmax'))  # Saída para múltiplas classes\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "\n",
    "# Calcular a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n",
    "\n",
    "# Relatório de classificação\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Gráfico de perda e acurácia durante o treinamento\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Perda de Treinamento')\n",
    "plt.plot(history.history['val_loss'], label='Perda de Validação')\n",
    "plt.title('Perda do Modelo')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Acurácia de Treinamento')\n",
    "plt.plot(history.history['val_accuracy'], label='Acurácia de Validação')\n",
    "plt.title('Acurácia do Modelo')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passengerid</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked_c</th>\n",
       "      <th>...</th>\n",
       "      <th>title_Ms</th>\n",
       "      <th>title_Rev</th>\n",
       "      <th>fare_group_Medium-Low Fare</th>\n",
       "      <th>fare_group_Medium-High Fare</th>\n",
       "      <th>fare_group_High Fare</th>\n",
       "      <th>sex_pclass_interaction_female_2</th>\n",
       "      <th>sex_pclass_interaction_female_3</th>\n",
       "      <th>sex_pclass_interaction_male_1</th>\n",
       "      <th>sex_pclass_interaction_male_2</th>\n",
       "      <th>sex_pclass_interaction_male_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>James</td>\n",
       "      <td>34.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>Unk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>James (Ellen Needs)</td>\n",
       "      <td>47.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>Unk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Thomas Francis</td>\n",
       "      <td>62.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>Unk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Albert</td>\n",
       "      <td>27.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>Unk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Alexander (Helga E Lindqvist)</td>\n",
       "      <td>22.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>Unk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Woolf</td>\n",
       "      <td>25.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Unk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Fermina</td>\n",
       "      <td>39.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Simon Sivertsen</td>\n",
       "      <td>38.500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Unk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Frederick</td>\n",
       "      <td>25.125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Unk</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Michael J</td>\n",
       "      <td>11.400</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>Unk</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     passengerid  pclass                           name     age  sibsp  parch  \\\n",
       "0            892       3                          James  34.500      0      0   \n",
       "1            893       3            James (Ellen Needs)  47.000      1      0   \n",
       "2            894       2                 Thomas Francis  62.000      0      0   \n",
       "3            895       3                         Albert  27.000      0      0   \n",
       "4            896       3  Alexander (Helga E Lindqvist)  22.000      1      1   \n",
       "..           ...     ...                            ...     ...    ...    ...   \n",
       "413         1305       3                          Woolf  25.125      0      0   \n",
       "414         1306       1                        Fermina  39.000      0      0   \n",
       "415         1307       3                Simon Sivertsen  38.500      0      0   \n",
       "416         1308       3                      Frederick  25.125      0      0   \n",
       "417         1309       3                      Michael J  11.400      1      1   \n",
       "\n",
       "                 ticket      fare cabin  embarked_c  ...  title_Ms  title_Rev  \\\n",
       "0                330911    7.8292   Unk           0  ...     False      False   \n",
       "1                363272    7.0000   Unk           0  ...     False      False   \n",
       "2                240276    9.6875   Unk           0  ...     False      False   \n",
       "3                315154    8.6625   Unk           0  ...     False      False   \n",
       "4               3101298   12.2875   Unk           0  ...     False      False   \n",
       "..                  ...       ...   ...         ...  ...       ...        ...   \n",
       "413           A.5. 3236    8.0500   Unk           0  ...     False      False   \n",
       "414            PC 17758  108.9000  C105           1  ...     False      False   \n",
       "415  SOTON/O.Q. 3101262    7.2500   Unk           0  ...     False      False   \n",
       "416              359309    8.0500   Unk           0  ...     False      False   \n",
       "417                2668   22.3583   Unk           1  ...     False      False   \n",
       "\n",
       "     fare_group_Medium-Low Fare fare_group_Medium-High Fare  \\\n",
       "0                         False                       False   \n",
       "1                         False                       False   \n",
       "2                          True                       False   \n",
       "3                          True                       False   \n",
       "4                          True                       False   \n",
       "..                          ...                         ...   \n",
       "413                        True                       False   \n",
       "414                       False                       False   \n",
       "415                       False                       False   \n",
       "416                        True                       False   \n",
       "417                       False                        True   \n",
       "\n",
       "     fare_group_High Fare  sex_pclass_interaction_female_2  \\\n",
       "0                   False                            False   \n",
       "1                   False                            False   \n",
       "2                   False                            False   \n",
       "3                   False                            False   \n",
       "4                   False                            False   \n",
       "..                    ...                              ...   \n",
       "413                 False                            False   \n",
       "414                  True                            False   \n",
       "415                 False                            False   \n",
       "416                 False                            False   \n",
       "417                 False                            False   \n",
       "\n",
       "     sex_pclass_interaction_female_3  sex_pclass_interaction_male_1  \\\n",
       "0                              False                          False   \n",
       "1                               True                          False   \n",
       "2                              False                          False   \n",
       "3                              False                          False   \n",
       "4                               True                          False   \n",
       "..                               ...                            ...   \n",
       "413                            False                          False   \n",
       "414                            False                          False   \n",
       "415                            False                          False   \n",
       "416                            False                          False   \n",
       "417                            False                          False   \n",
       "\n",
       "     sex_pclass_interaction_male_2  sex_pclass_interaction_male_3  \n",
       "0                            False                           True  \n",
       "1                            False                          False  \n",
       "2                             True                          False  \n",
       "3                            False                           True  \n",
       "4                            False                          False  \n",
       "..                             ...                            ...  \n",
       "413                          False                           True  \n",
       "414                          False                          False  \n",
       "415                          False                           True  \n",
       "416                          False                           True  \n",
       "417                          False                           True  \n",
       "\n",
       "[418 rows x 48 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adiciona o diretório 'Scripts' ao sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..','Scripts')))\n",
    "from preprocessing import preprocess_data\n",
    "from test_feature import engineer_features\n",
    "\n",
    "# Define o caminho relativo\n",
    "file_path = os.path.join('..', 'Data', 'test.csv')  # '..' sobe um nível de diretório\n",
    "\n",
    "# Carrega os dados\n",
    "df_test = pd.read_csv(file_path)\n",
    "\n",
    "df_test = preprocess_data(df_test)\n",
    "df_test = engineer_features(df_test)\n",
    "df_test = transform_specific_columns_to_int(df_test)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo de submissão criado com sucesso!\n"
     ]
    }
   ],
   "source": [
    "# Adiciona o diretório 'Scripts' ao sys.path\n",
    "\n",
    "#X_test_final = pd.get_dummies(df_test[features], drop_first=True)\n",
    "\n",
    "# Alinhar as colunas do conjunto de teste com as do conjunto de treino\n",
    "X_test_final = df_test.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Fazer previsões com o modelo treinado\n",
    "predictions = best_model.predict(X_test_final)\n",
    "\n",
    "# Criar o DataFrame de submissão\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': df_test['passengerid'],  # Certifique-se de que `PassengerId` está no df_test\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Salvar o arquivo de submissão como CSV\n",
    "submission_df.to_csv('C:\\\\Users\\\\Guilherme\\\\OneDrive\\\\Área de Trabalho\\\\submission3.csv', index=False)\n",
    "\n",
    "print(\"Arquivo de submissão criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adiciona o diretório 'Scripts' ao sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..','Scripts')))\n",
    "from preprocessing import preprocess_data\n",
    "from test_feature import engineer_features\n",
    "\n",
    "# Define o caminho relativo\n",
    "file_path = os.path.join('..', 'Data', 'test.csv')  # '..' sobe um nível de diretório\n",
    "\n",
    "# Carrega os dados\n",
    "df_test = pd.read_csv(file_path)\n",
    "\n",
    "df_test = preprocess_data(df_test)\n",
    "df_test = engineer_features(df_test)\n",
    "\n",
    "\n",
    "X_test_final = pd.get_dummies(df_test[features], drop_first=True)\n",
    "\n",
    "# Alinhar as colunas do conjunto de teste com as do conjunto de treino\n",
    "X_test_final = X_test_final.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Fazer previsões com o modelo treinado\n",
    "predictions = model.predict(X_test_final)\n",
    "\n",
    "# Criar o DataFrame de submissão\n",
    "submission_df = pd.DataFrame({\n",
    "    'PassengerId': df_test['passengerid'],  # Certifique-se de que `PassengerId` está no df_test\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Salvar o arquivo de submissão como CSV\n",
    "submission_df.to_csv('C:\\\\Users\\\\Guilherme\\\\OneDrive\\\\Área de Trabalho\\\\submission.csv', index=False)\n",
    "\n",
    "print(\"Arquivo de submissão criado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
